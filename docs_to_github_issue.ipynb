{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parses PDF files and extracts numbered items from them into a list and then creates a github project with the list of items as issues.\n",
    "\n",
    "This notebook reuses the code from the following notebooks:\n",
    "- [ColPali_+_Qwen2_VL.ipynb](https://github.com/merveenoyan/smol-vision/blob/main/ColPali_%2B_Qwen2_VL.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install python-dotenv\n",
    "%pip install --upgrade byaldi\n",
    "\n",
    "# %sudo apt-get install -y poppler-utils # is there a mac equivalent?\n",
    "\n",
    "%pip install -q pdf2image git+https://github.com/huggingface/transformers.git qwen-vl-utils flash-attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owner ID: MDQ6VXNlcjI2MzU4MDQ3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from byaldi import RAGMultiModalModel\n",
    "from pdf2image import convert_from_path\n",
    "from huggingface_hub import notebook_login\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "\n",
    "notebook_login()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "asset_dir = \"assets/\"\n",
    "\n",
    "files = [f for f in os.listdir(asset_dir) if os.path.isfile(os.path.join(asset_dir, f))]\n",
    "\n",
    "print(files)\n",
    "\n",
    "images = convert_from_path(asset_dir + files[0]) # TODO: loop through all files\n",
    "images[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAG = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG.index(\n",
    "    input_path= f\"{asset_dir}{files[0]}\", # path to the input file\n",
    "    index_name=\"image_index\", # index will be saved at index_root/index_name/\n",
    "    store_collection_with_index=False,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = \"How many issues are there in the image?\"\n",
    "results = RAG.search(text_query, k=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "                                                        trust_remote_code=True, torch_dtype=torch.bfloat16).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", trust_remote_code=True)\n",
    "\n",
    "image_index = results[0][\"page_num\"] - 1\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": images[image_index],\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": text_query},\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these variables with your own values\n",
    "github_token =  os.getenv('GITHUB_PROJECT_SCOPE_PAT')\n",
    "github_owner = os.getenv('GITHUB_OWNER')\n",
    "\n",
    "\n",
    "token = github_token\n",
    "owner = github_owner\n",
    "project_name = 'First Project'\n",
    "issue_title = 'Issue Title'\n",
    "issue_body = 'Issue Body'\n",
    "\n",
    "# Get the node ID of the owner\n",
    "owner_url = f'https://api.github.com/users/{owner}'\n",
    "headers = {\n",
    "    'Authorization': f'token {token}',\n",
    "    'Accept': 'application/vnd.github+json'\n",
    "}\n",
    "response = requests.get(owner_url, headers=headers)\n",
    "owner_id = response.json()['node_id']\n",
    "print(\"Owner ID:\", owner_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the project\n",
    "create_project_query = {\n",
    "    'query': f'mutation {{createProjectV2(input: {{ownerId: \"{owner_id}\", title: \"{project_name}\"}}) {{projectV2 {{id}}}}}}'\n",
    "}\n",
    "response = requests.post('https://api.github.com/graphql', headers=headers, data=json.dumps(create_project_query))\n",
    "print(response.json())\n",
    "project_id = response.json()['data']['createProjectV2']['projectV2']['id']\n",
    "print(\"Project ID:\", project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignees = ['tunji17']  # GitHub usernames of the assignees\n",
    "\n",
    "# Get the node IDs of the assignees\n",
    "assignee_ids = []\n",
    "for assignee in assignees:\n",
    "    assignee_url = f'https://api.github.com/users/{assignee}'\n",
    "    response = requests.get(assignee_url, headers=headers)\n",
    "    assignee_ids.append(response.json()['node_id'])\n",
    "\n",
    "assignees_str = ', '.join([f'\"{assignee_id}\"' for assignee_id in assignee_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a draft issue to the project\n",
    "add_issue_query = {\n",
    "    'query': f'mutation {{addProjectV2DraftIssue(input: {{projectId: \"{project_id}\", title: \"{issue_title}\", body: \"{issue_body}\", assigneeIds: [{assignees_str}]}}) {{projectItem {{id}}}}}}'\n",
    "}\n",
    "response = requests.post('https://api.github.com/graphql', headers=headers, data=json.dumps(add_issue_query))\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automation_pipeline-Hmt1h5RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
